{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f667193a-7cbd-452e-b34e-b113a3bcb79f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: cmake in c:\\users\\udayk\\anaconda3\\lib\\site-packages (4.0.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install cmake "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "de1b2d00-db25-4608-b317-493b8a28b2ce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using pip 25.0.1 from C:\\Users\\udayk\\AppData\\Roaming\\Python\\Python312\\site-packages\\pip (python 3.12)\n",
      "Requirement already satisfied: dlib in c:\\users\\udayk\\anaconda3\\lib\\site-packages (19.24.8)\n"
     ]
    }
   ],
   "source": [
    "!pip install dlib --verbose"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "83637e8f-7706-4a0c-b145-6d07fe43dfd5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: face_recognition==1.3.0 in c:\\users\\udayk\\anaconda3\\lib\\site-packages (1.3.0)\n",
      "Requirement already satisfied: face-recognition-models>=0.3.0 in c:\\users\\udayk\\anaconda3\\lib\\site-packages (from face_recognition==1.3.0) (0.3.0)\n",
      "Requirement already satisfied: Click>=6.0 in c:\\users\\udayk\\appdata\\roaming\\python\\python312\\site-packages (from face_recognition==1.3.0) (8.1.8)\n",
      "Requirement already satisfied: dlib>=19.7 in c:\\users\\udayk\\anaconda3\\lib\\site-packages (from face_recognition==1.3.0) (19.24.8)\n",
      "Requirement already satisfied: numpy in c:\\users\\udayk\\anaconda3\\lib\\site-packages (from face_recognition==1.3.0) (1.26.4)\n",
      "Requirement already satisfied: Pillow in c:\\users\\udayk\\anaconda3\\lib\\site-packages (from face_recognition==1.3.0) (10.3.0)\n",
      "Requirement already satisfied: colorama in c:\\users\\udayk\\appdata\\roaming\\python\\python312\\site-packages (from Click>=6.0->face_recognition==1.3.0) (0.4.6)\n"
     ]
    }
   ],
   "source": [
    "!pip install numpy==1.26.4 opencv-python==4.11.0.86 pillow==10.3.0 ipywidgets==7.8.1 \n",
    "!pip install face_recognition==1.3.0 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "77654813-a773-4db5-9b57-0c6be342f0bc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting git+https://github.com/ageitgey/face_recognition_models\n",
      "  Cloning https://github.com/ageitgey/face_recognition_models to c:\\users\\udayk\\appdata\\local\\temp\\pip-req-build-c3vgz3b8\n",
      "  Resolved https://github.com/ageitgey/face_recognition_models to commit e67de717267507d1e9246de95692eb8be736ab61\n",
      "  Preparing metadata (setup.py): started\n",
      "  Preparing metadata (setup.py): finished with status 'done'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  Running command git clone --filter=blob:none --quiet https://github.com/ageitgey/face_recognition_models 'C:\\Users\\udayk\\AppData\\Local\\Temp\\pip-req-build-c3vgz3b8'\n"
     ]
    }
   ],
   "source": [
    "!pip install git+https://github.com/ageitgey/face_recognition_models "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9ea2b258-8b1c-4eb5-953b-d8ccd5a4db65",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: scikit-learn in c:\\users\\udayk\\anaconda3\\lib\\site-packages (1.4.2)\n",
      "Requirement already satisfied: numpy>=1.19.5 in c:\\users\\udayk\\anaconda3\\lib\\site-packages (from scikit-learn) (1.26.4)\n",
      "Requirement already satisfied: scipy>=1.6.0 in c:\\users\\udayk\\appdata\\roaming\\python\\python312\\site-packages (from scikit-learn) (1.14.1)\n",
      "Requirement already satisfied: joblib>=1.2.0 in c:\\users\\udayk\\appdata\\roaming\\python\\python312\\site-packages (from scikit-learn) (1.4.2)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in c:\\users\\udayk\\appdata\\roaming\\python\\python312\\site-packages (from scikit-learn) (3.5.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install scikit-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c7b89a41-db9e-4667-b7f6-407786bc5084",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: tensorflow in c:\\users\\udayk\\anaconda3\\lib\\site-packages (2.19.0)\n",
      "Requirement already satisfied: absl-py>=1.0.0 in c:\\users\\udayk\\appdata\\roaming\\python\\python312\\site-packages (from tensorflow) (2.2.2)\n",
      "Requirement already satisfied: astunparse>=1.6.0 in c:\\users\\udayk\\appdata\\roaming\\python\\python312\\site-packages (from tensorflow) (1.6.3)\n",
      "Requirement already satisfied: flatbuffers>=24.3.25 in c:\\users\\udayk\\appdata\\roaming\\python\\python312\\site-packages (from tensorflow) (25.2.10)\n",
      "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in c:\\users\\udayk\\appdata\\roaming\\python\\python312\\site-packages (from tensorflow) (0.6.0)\n",
      "Requirement already satisfied: google-pasta>=0.1.1 in c:\\users\\udayk\\appdata\\roaming\\python\\python312\\site-packages (from tensorflow) (0.2.0)\n",
      "Requirement already satisfied: libclang>=13.0.0 in c:\\users\\udayk\\appdata\\roaming\\python\\python312\\site-packages (from tensorflow) (18.1.1)\n",
      "Requirement already satisfied: opt-einsum>=2.3.2 in c:\\users\\udayk\\appdata\\roaming\\python\\python312\\site-packages (from tensorflow) (3.4.0)\n",
      "Requirement already satisfied: packaging in c:\\users\\udayk\\appdata\\roaming\\python\\python312\\site-packages (from tensorflow) (24.2)\n",
      "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<6.0.0dev,>=3.20.3 in c:\\users\\udayk\\appdata\\roaming\\python\\python312\\site-packages (from tensorflow) (5.29.4)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in c:\\users\\udayk\\appdata\\roaming\\python\\python312\\site-packages (from tensorflow) (2.32.3)\n",
      "Requirement already satisfied: setuptools in c:\\users\\udayk\\appdata\\roaming\\python\\python312\\site-packages (from tensorflow) (75.6.0)\n",
      "Requirement already satisfied: six>=1.12.0 in c:\\users\\udayk\\appdata\\roaming\\python\\python312\\site-packages (from tensorflow) (1.17.0)\n",
      "Requirement already satisfied: termcolor>=1.1.0 in c:\\users\\udayk\\appdata\\roaming\\python\\python312\\site-packages (from tensorflow) (3.0.1)\n",
      "Requirement already satisfied: typing-extensions>=3.6.6 in c:\\users\\udayk\\appdata\\roaming\\python\\python312\\site-packages (from tensorflow) (4.12.2)\n",
      "Requirement already satisfied: wrapt>=1.11.0 in c:\\users\\udayk\\appdata\\roaming\\python\\python312\\site-packages (from tensorflow) (1.17.2)\n",
      "Requirement already satisfied: grpcio<2.0,>=1.24.3 in c:\\users\\udayk\\appdata\\roaming\\python\\python312\\site-packages (from tensorflow) (1.71.0)\n",
      "Requirement already satisfied: tensorboard~=2.19.0 in c:\\users\\udayk\\appdata\\roaming\\python\\python312\\site-packages (from tensorflow) (2.19.0)\n",
      "Requirement already satisfied: keras>=3.5.0 in c:\\users\\udayk\\appdata\\roaming\\python\\python312\\site-packages (from tensorflow) (3.9.2)\n",
      "Requirement already satisfied: numpy<2.2.0,>=1.26.0 in c:\\users\\udayk\\anaconda3\\lib\\site-packages (from tensorflow) (1.26.4)\n",
      "Requirement already satisfied: h5py>=3.11.0 in c:\\users\\udayk\\appdata\\roaming\\python\\python312\\site-packages (from tensorflow) (3.13.0)\n",
      "Requirement already satisfied: ml-dtypes<1.0.0,>=0.5.1 in c:\\users\\udayk\\appdata\\roaming\\python\\python312\\site-packages (from tensorflow) (0.5.1)\n",
      "Requirement already satisfied: wheel<1.0,>=0.23.0 in c:\\users\\udayk\\appdata\\roaming\\python\\python312\\site-packages (from astunparse>=1.6.0->tensorflow) (0.45.1)\n",
      "Requirement already satisfied: rich in c:\\users\\udayk\\appdata\\roaming\\python\\python312\\site-packages (from keras>=3.5.0->tensorflow) (13.9.4)\n",
      "Requirement already satisfied: namex in c:\\users\\udayk\\appdata\\roaming\\python\\python312\\site-packages (from keras>=3.5.0->tensorflow) (0.0.8)\n",
      "Requirement already satisfied: optree in c:\\users\\udayk\\appdata\\roaming\\python\\python312\\site-packages (from keras>=3.5.0->tensorflow) (0.15.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\udayk\\appdata\\roaming\\python\\python312\\site-packages (from requests<3,>=2.21.0->tensorflow) (3.4.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\udayk\\appdata\\roaming\\python\\python312\\site-packages (from requests<3,>=2.21.0->tensorflow) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\udayk\\appdata\\roaming\\python\\python312\\site-packages (from requests<3,>=2.21.0->tensorflow) (2.2.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\udayk\\appdata\\roaming\\python\\python312\\site-packages (from requests<3,>=2.21.0->tensorflow) (2024.12.14)\n",
      "Requirement already satisfied: markdown>=2.6.8 in c:\\users\\udayk\\appdata\\roaming\\python\\python312\\site-packages (from tensorboard~=2.19.0->tensorflow) (3.8)\n",
      "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in c:\\users\\udayk\\appdata\\roaming\\python\\python312\\site-packages (from tensorboard~=2.19.0->tensorflow) (0.7.2)\n",
      "Requirement already satisfied: werkzeug>=1.0.1 in c:\\users\\udayk\\appdata\\roaming\\python\\python312\\site-packages (from tensorboard~=2.19.0->tensorflow) (3.1.3)\n",
      "Requirement already satisfied: MarkupSafe>=2.1.1 in c:\\users\\udayk\\appdata\\roaming\\python\\python312\\site-packages (from werkzeug>=1.0.1->tensorboard~=2.19.0->tensorflow) (3.0.2)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in c:\\users\\udayk\\appdata\\roaming\\python\\python312\\site-packages (from rich->keras>=3.5.0->tensorflow) (3.0.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in c:\\users\\udayk\\appdata\\roaming\\python\\python312\\site-packages (from rich->keras>=3.5.0->tensorflow) (2.18.0)\n",
      "Requirement already satisfied: mdurl~=0.1 in c:\\users\\udayk\\appdata\\roaming\\python\\python312\\site-packages (from markdown-it-py>=2.2.0->rich->keras>=3.5.0->tensorflow) (0.1.2)\n"
     ]
    }
   ],
   "source": [
    "!pip install tensorflow\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "10795318-1c17-4b47-aca8-fa8331b4761b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All imports successful!\n"
     ]
    }
   ],
   "source": [
    "import face_recognition\n",
    "import cv2\n",
    "import numpy as np\n",
    "import PIL\n",
    "import ipywidgets\n",
    "print(\"All imports successful!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "22ad4c67-80bd-4fdb-8a3a-914c18fdb01a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "62ef540471884c5797b5c97f9bf42652",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(HBox(children=(Text(value='', description='Folder Path:', placeholder='Enter folder path'),)), …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import os\n",
    "from collections import defaultdict\n",
    "import io\n",
    "from PIL import Image\n",
    "import zipfile\n",
    "from pathlib import Path\n",
    "import uuid\n",
    "import time\n",
    "from IPython.display import display, HTML, FileLink, clear_output\n",
    "import base64\n",
    "import ipywidgets as widgets\n",
    "from ipywidgets import Text, Button, Output, HBox, VBox, FloatProgress\n",
    "import face_recognition\n",
    "\n",
    "# Updated UI HTML/CSS with 3-column grid, larger cells, sequential face numbers, and no share options\n",
    "after_ui_html = \"\"\"\n",
    "<style>\n",
    "    * {{\n",
    "        margin: 0;\n",
    "        padding: 0;\n",
    "        box-sizing: border-box;\n",
    "        font-family: 'Roboto', -apple-system, BlinkMacSystemFont, 'Segoe UI', sans-serif;\n",
    "    }}\n",
    "    .container {{\n",
    "        background: #ffffff;\n",
    "        border-radius: 12px;\n",
    "        box-shadow: 0 4px 20px rgba(0, 0, 0, 0.08);\n",
    "        padding: 30px;\n",
    "        width: 100%;\n",
    "        max-width: 1200px;\n",
    "        color: #202124;\n",
    "        margin: 30px auto;\n",
    "        border: 1px solid #dadce0;\n",
    "    }}\n",
    "    h1 {{\n",
    "        text-align: center;\n",
    "        margin-bottom: 25px;\n",
    "        color: #202124;\n",
    "        font-size: 28px;\n",
    "        font-weight: 500;\n",
    "        letter-spacing: -0.3px;\n",
    "    }}\n",
    "    #output {{\n",
    "        background: #f1f3f4;\n",
    "        border: 1px solid #dadce0;\n",
    "        border-radius: 8px;\n",
    "        padding: 20px;\n",
    "        min-height: 200px;\n",
    "        font-size: 14px;\n",
    "        line-height: 1.6;\n",
    "        white-space: pre-wrap;\n",
    "        color: #5f6368;\n",
    "        overflow-y: auto;\n",
    "        box-shadow: inset 0 1px 3px rgba(0, 0, 0, 0.03);\n",
    "    }}\n",
    "    a {{\n",
    "        color: #1a73e8;\n",
    "        text-decoration: none;\n",
    "        font-weight: 500;\n",
    "        transition: color 0.2s ease;\n",
    "    }}\n",
    "    a:hover {{\n",
    "        color: #1557b0;\n",
    "        text-decoration: underline;\n",
    "    }}\n",
    "    .face-group {{\n",
    "        margin-bottom: 30px;\n",
    "    }}\n",
    "    .face-label {{\n",
    "        font-size: 18px;\n",
    "        font-weight: 500;\n",
    "        color: #202124;\n",
    "        margin-bottom: 10px;\n",
    "        background: #e8f0fe;\n",
    "        padding: 8px 12px;\n",
    "        border-radius: 4px;\n",
    "        display: inline-block;\n",
    "    }}\n",
    "    .image-grid {{\n",
    "        display: grid;\n",
    "        grid-template-columns: repeat(3, 1fr);\n",
    "        gap: 12px;\n",
    "    }}\n",
    "    .image-card {{\n",
    "        position: relative;\n",
    "        width: 100%;\n",
    "        aspect-ratio: 1 / 1;\n",
    "        min-height: 250px;\n",
    "        overflow: hidden;\n",
    "        border-radius: 4px;\n",
    "        cursor: pointer;\n",
    "    }}\n",
    "    .image-card img {{\n",
    "        width: 100%;\n",
    "        height: 100%;\n",
    "        object-fit: cover;\n",
    "        border-radius: 4px;\n",
    "        display: block;\n",
    "        transition: filter 0.2s ease;\n",
    "    }}\n",
    "    .image-overlay {{\n",
    "        position: absolute;\n",
    "        top: 0;\n",
    "        left: 0;\n",
    "        right: 0;\n",
    "        bottom: 0;\n",
    "        background: rgba(0, 0, 0, 0.4);\n",
    "        opacity: 0;\n",
    "        border-radius: 4px;\n",
    "        display: flex;\n",
    "        flex-direction: column;\n",
    "        justify-content: space-between;\n",
    "        padding: 8px;\n",
    "        transition: opacity 0.2s ease;\n",
    "    }}\n",
    "    .image-card:hover .image-overlay {{\n",
    "        opacity: 1;\n",
    "    }}\n",
    "    .image-card:hover img {{\n",
    "        filter: brightness(80%);\n",
    "    }}\n",
    "    .group-label {{\n",
    "        font-size: 13px;\n",
    "        font-weight: 500;\n",
    "        color: #ffffff;\n",
    "        background: rgba(0, 0, 0, 0.6);\n",
    "        padding: 4px 8px;\n",
    "        border-radius: 12px;\n",
    "        display: inline-block;\n",
    "        align-self: flex-start;\n",
    "    }}\n",
    "    .image-filename {{\n",
    "        font-size: 12px;\n",
    "        color: #ffffff;\n",
    "        text-align: left;\n",
    "        word-break: break-all;\n",
    "        background: rgba(0, 0, 0, 0.6);\n",
    "        padding: 4px 8px;\n",
    "        border-radius: 4px;\n",
    "    }}\n",
    "    .modal {{\n",
    "        display: none;\n",
    "        position: fixed;\n",
    "        top: 0;\n",
    "        left: 0;\n",
    "        width: 100%;\n",
    "        height: 100%;\n",
    "        background: rgba(0, 0, 0, 0.9);\n",
    "        z-index: 1000;\n",
    "        justify-content: center;\n",
    "        align-items: center;\n",
    "    }}\n",
    "    .modal-content {{\n",
    "        max-width: 90%;\n",
    "        max-height: 90%;\n",
    "        object-fit: contain;\n",
    "    }}\n",
    "    .close-btn {{\n",
    "        position: absolute;\n",
    "        top: 20px;\n",
    "        right: 20px;\n",
    "        color: #ffffff;\n",
    "        font-size: 30px;\n",
    "        font-weight: bold;\n",
    "        cursor: pointer;\n",
    "        background: none;\n",
    "        border: none;\n",
    "    }}\n",
    "</style>\n",
    "<div class=\"container\">\n",
    "    <h1>Face Grouping Results</h1>\n",
    "    <div id=\"output\">{}</div>\n",
    "    <div id=\"modal\" class=\"modal\">\n",
    "        <button class=\"close-btn\" onclick=\"document.getElementById('modal').style.display='none'\">×</button>\n",
    "        <img class=\"modal-content\" id=\"modal-image\">\n",
    "    </div>\n",
    "</div>\n",
    "<script>\n",
    "    function showFullScreen(src) {{\n",
    "        const modal = document.getElementById('modal');\n",
    "        const modalImage = document.getElementById('modal-image');\n",
    "        modalImage.src = src;\n",
    "        modal.style.display = 'flex';\n",
    "    }}\n",
    "</script>\n",
    "\"\"\"\n",
    "\n",
    "# Preprocess image for consistent detection and size reduction\n",
    "def preprocess_image(image_array, filename=\"unknown\"):\n",
    "    try:\n",
    "        max_size = 800\n",
    "        h, w = image_array.shape[:2]\n",
    "        if max(h, w) > max_size:\n",
    "            scale = max_size / max(h, w)\n",
    "            image_array = cv2.resize(image_array, (int(w * scale), int(h * scale)), interpolation=cv2.INTER_AREA)\n",
    "        \n",
    "        pil_image = Image.fromarray(image_array)\n",
    "        buffer = io.BytesIO()\n",
    "        pil_image.save(buffer, format=\"JPEG\", quality=85)\n",
    "        compressed_image = np.array(Image.open(buffer), dtype=np.uint8)\n",
    "        \n",
    "        if compressed_image.shape[-1] == 4:\n",
    "            compressed_image = cv2.cvtColor(compressed_image, cv2.COLOR_RGBA2RGB)\n",
    "        elif len(compressed_image.shape) == 2:\n",
    "            compressed_image = cv2.cvtColor(compressed_image, cv2.COLOR_GRAY2RGB)\n",
    "            \n",
    "        return compressed_image\n",
    "    except Exception as e:\n",
    "        print(f\"Error preprocessing {filename}: {str(e)}\")\n",
    "        return None\n",
    "\n",
    "# Extract face encodings and locations with HOG\n",
    "def get_face_encodings_and_locations(image_data, filename=\"unknown\"):\n",
    "    try:\n",
    "        image = Image.open(io.BytesIO(image_data))\n",
    "        if image.mode != 'RGB':\n",
    "            print(f\"Converting {filename} from {image.mode} to RGB\")\n",
    "            image = image.convert('RGB')\n",
    "        buffer = io.BytesIO()\n",
    "        image.save(buffer, format=\"JPEG\")\n",
    "        image_array = np.array(Image.open(buffer), dtype=np.uint8)\n",
    "        if image_array.dtype != np.uint8 or len(image_array.shape) != 3 or image_array.shape[2] != 3:\n",
    "            raise ValueError(f\"Invalid format for {filename}: Shape {image_array.shape}, Dtype {image_array.dtype}\")\n",
    "\n",
    "        image_array = preprocess_image(image_array, filename)\n",
    "        if image_array is None:\n",
    "            return [], [], None\n",
    "            \n",
    "        face_locations = face_recognition.face_locations(image_array, model=\"hog\")\n",
    "        if not face_locations:\n",
    "            return [], [], image_array\n",
    "        encodings = face_recognition.face_encodings(image_array, face_locations, num_jitters=3)\n",
    "        return encodings, face_locations, image_array\n",
    "    except Exception as e:\n",
    "        print(f\"Error processing {filename}: {str(e)}\")\n",
    "        return [], [], None\n",
    "\n",
    "# Load images from folder with size check\n",
    "def load_images(folder_path, progress_bar=None, output=None):\n",
    "    uploaded_files = {}\n",
    "    if not os.path.isdir(folder_path):\n",
    "        print(f\"Invalid folder path: {folder_path}\")\n",
    "        return uploaded_files\n",
    "    image_files = [f for f in os.listdir(folder_path) if f.lower().endswith(('.png', '.jpg', '.jpeg'))]\n",
    "    total_files = len(image_files)\n",
    "    \n",
    "    max_file_size = 5 * 1024 * 1024\n",
    "    for i, filename in enumerate(image_files):\n",
    "        file_path = os.path.join(folder_path, filename)\n",
    "        file_size = os.path.getsize(file_path)\n",
    "        \n",
    "        if file_size > max_file_size:\n",
    "            print(f\"Skipping {filename}: File size ({file_size / 1024 / 1024:.2f}MB) exceeds 5MB limit.\")\n",
    "            continue\n",
    "            \n",
    "        try:\n",
    "            with open(file_path, 'rb') as f:\n",
    "                image_data = f.read()\n",
    "            \n",
    "            if len(image_data) > 1 * 1024 * 1024:\n",
    "                image = Image.open(io.BytesIO(image_data))\n",
    "                if image.mode != 'RGB':\n",
    "                    image = image.convert('RGB')\n",
    "                buffer = io.BytesIO()\n",
    "                image.save(buffer, format=\"JPEG\", quality=75)\n",
    "                image_data = buffer.getvalue()\n",
    "                print(f\"Compressed {filename} to {len(image_data) / 1024 / 1024:.2f}MB\")\n",
    "                \n",
    "            uploaded_files[filename] = {'content': image_data, 'original_name': filename}\n",
    "        except Exception as e:\n",
    "            print(f\"Error loading {filename}: {str(e)}\")\n",
    "            continue\n",
    "            \n",
    "        if progress_bar:\n",
    "            progress_bar.value = (i + 1) / total_files\n",
    "        if output:\n",
    "            with output:\n",
    "                clear_output(wait=True)\n",
    "                print(f\"Loading {i + 1}/{total_files}: {filename}\")\n",
    "    return uploaded_files\n",
    "\n",
    "# Group similar faces\n",
    "def group_similar_faces(uploaded_files, progress_bar=None, output=None):\n",
    "    all_encodings = []\n",
    "    all_filenames = []\n",
    "    all_image_data = []\n",
    "    processed_images = 0\n",
    "    total_files = len(uploaded_files)\n",
    "\n",
    "    for i, (filename, file_info) in enumerate(uploaded_files.items()):\n",
    "        image_data = file_info['content']\n",
    "        encodings, _, _ = get_face_encodings_and_locations(image_data, filename)\n",
    "        if encodings:\n",
    "            processed_images += 1\n",
    "            for encoding in encodings:\n",
    "                all_encodings.append(encoding)\n",
    "                all_filenames.append(filename)\n",
    "                all_image_data.append(image_data)\n",
    "        if progress_bar:\n",
    "            progress_bar.value = (i + 1) / total_files\n",
    "        if output:\n",
    "            with output:\n",
    "                clear_output(wait=True)\n",
    "                print(f\"Processing {i + 1}/{total_files}: {filename}\")\n",
    "\n",
    "    if not all_encodings:\n",
    "        return defaultdict(list), processed_images\n",
    "\n",
    "    groups = []\n",
    "    threshold = 0.45\n",
    "    for encoding, filename, image_data in zip(all_encodings, all_filenames, all_image_data):\n",
    "        matched = False\n",
    "        for group in groups:\n",
    "            if face_recognition.face_distance([group[0]['encoding']], encoding)[0] < threshold:\n",
    "                group.append({'encoding': encoding, 'filename': filename, 'image_data': image_data})\n",
    "                matched = True\n",
    "                break\n",
    "        if not matched:\n",
    "            groups.append([{'encoding': encoding, 'filename': filename, 'image_data': image_data}])\n",
    "\n",
    "    refined_groups = {f\"Face {i+1}\": group for i, group in enumerate(groups)}\n",
    "    return refined_groups, processed_images\n",
    "\n",
    "# Save grouped faces and create ZIP\n",
    "def save_grouped_faces_and_zip(face_groups, output_folder, uploaded_files):\n",
    "    zip_files = []\n",
    "    file_mapping = {}\n",
    "    os.makedirs(output_folder, exist_ok=True)\n",
    "    for group_id, faces in face_groups.items():\n",
    "        group_folder = os.path.join(output_folder, f\"{group_id}\")\n",
    "        Path(group_folder).mkdir(exist_ok=True)\n",
    "        saved_filenames = set()\n",
    "        for face_data in faces:\n",
    "            original_name = uploaded_files[face_data['filename']]['original_name']\n",
    "            if original_name not in saved_filenames:\n",
    "                unique_name = f\"{os.path.splitext(original_name)[0]}_{uuid.uuid4().hex[:8]}{os.path.splitext(original_name)[1]}\"\n",
    "                dest_path = os.path.join(group_folder, unique_name)\n",
    "                with open(dest_path, 'wb') as f:\n",
    "                    f.write(face_data['image_data'])\n",
    "                file_mapping[(group_id, original_name)] = dest_path\n",
    "                saved_filenames.add(original_name)\n",
    "        print(f\"Saved {len(saved_filenames)} images for {group_id}\")\n",
    "\n",
    "    zip_filename = \"all_faces.zip\"\n",
    "    zip_path = os.path.join(output_folder, zip_filename)\n",
    "    with zipfile.ZipFile(zip_path, 'w', zipfile.ZIP_DEFLATED) as zipf:\n",
    "        for group_id, faces in face_groups.items():\n",
    "            saved_filenames = set()\n",
    "            for face_data in faces:\n",
    "                original_name = uploaded_files[face_data['filename']]['original_name']\n",
    "                if original_name not in saved_filenames:\n",
    "                    image_path = file_mapping.get((group_id, original_name))\n",
    "                    if image_path and os.path.exists(image_path):\n",
    "                        zipf.write(image_path, os.path.join(f\"{group_id}\", os.path.basename(image_path)))\n",
    "                        saved_filenames.add(original_name)\n",
    "    zip_files.append(zip_path)\n",
    "    print(f\"ZIP created at: {zip_path}\")\n",
    "    return zip_files, file_mapping\n",
    "\n",
    "# Display images in separate 3-column grids for each face group with full-screen functionality\n",
    "def display_grouped_images(face_groups, file_mapping):\n",
    "    global uploaded_files\n",
    "    if not file_mapping:\n",
    "        return \"<p>No images to display.</p>\"\n",
    "    \n",
    "    grouped_images = defaultdict(list)\n",
    "    for (group_id, original_name), image_path in file_mapping.items():\n",
    "        grouped_images[group_id].append((original_name, image_path))\n",
    "    \n",
    "    image_html = \"\"\n",
    "    for group_id, images in sorted(grouped_images.items(), key=lambda x: int(x[0].split()[-1])):\n",
    "        image_html += f\"\"\"\n",
    "        <div class='face-group'>\n",
    "            <div class='face-label'>{group_id}</div>\n",
    "            <div class='image-grid'>\n",
    "        \"\"\"\n",
    "        for original_name, image_path in images:\n",
    "            try:\n",
    "                with open(image_path, 'rb') as f:\n",
    "                    image_data = f.read()\n",
    "                image_base64 = base64.b64encode(image_data).decode('utf-8')\n",
    "                image_html += f\"\"\"\n",
    "                <div class='image-card' onclick=\"showFullScreen('data:image/jpeg;base64,{image_base64}')\">\n",
    "                    <img src='data:image/jpeg;base64,{image_base64}' alt='{group_id}'>\n",
    "                    <div class='image-overlay'>\n",
    "                        <div class='group-label'>{group_id}</div>\n",
    "                        <div class='image-filename'>{os.path.basename(image_path)}</div>\n",
    "                    </div>\n",
    "                </div>\n",
    "                \"\"\"\n",
    "            except Exception as e:\n",
    "                print(f\"Error displaying {image_path}: {str(e)}\")\n",
    "        image_html += \"</div></div>\"\n",
    "    \n",
    "    return image_html\n",
    "\n",
    "# Webcam face recognition and match without share options\n",
    "def recognize_face_from_webcam(face_groups, uploaded_files, output_folder, file_mapping, output_widget):\n",
    "    cap = cv2.VideoCapture(0)\n",
    "    if not cap.isOpened():\n",
    "        with output_widget:\n",
    "            print(\"Error: Could not open webcam.\")\n",
    "        return None\n",
    "    while True:\n",
    "        ret, frame = cap.read()\n",
    "        if not ret:\n",
    "            with output_widget:\n",
    "                print(\"Error: Could not read frame.\")\n",
    "            break\n",
    "        rgb_frame = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "        face_locations = face_recognition.face_locations(rgb_frame, model=\"hog\")\n",
    "        if face_locations:\n",
    "            encodings = face_recognition.face_encodings(rgb_frame, face_locations)\n",
    "            for encoding in encodings:\n",
    "                for group_id, faces in face_groups.items():\n",
    "                    group_encodings = [f['encoding'] for f in faces]\n",
    "                    distances = face_recognition.face_distance(group_encodings, encoding)\n",
    "                    if min(distances) < 0.45:\n",
    "                        cap.release()\n",
    "                        cv2.destroyAllWindows()\n",
    "                        with output_widget:\n",
    "                            clear_output()\n",
    "                            print(f\"Match found: {group_id}\")\n",
    "\n",
    "                            # Create ZIP for matched group\n",
    "                            zip_path = os.path.join(output_folder, f\"{group_id}.zip\")\n",
    "                            with zipfile.ZipFile(zip_path, 'w', zipfile.ZIP_DEFLATED) as zipf:\n",
    "                                for (g_id, _), image_path in file_mapping.items():\n",
    "                                    if g_id == group_id:\n",
    "                                        zipf.write(image_path, os.path.basename(image_path))\n",
    "                            relative_path = os.path.relpath(zip_path, start=os.getcwd())\n",
    "\n",
    "                            # Display result with only download option\n",
    "                            result_html = (f\"Matched face group: {group_id}. \"\n",
    "                                          f\"<a href='{relative_path}' download='{group_id}.zip'>Download matched group</a>\")\n",
    "                            with output_widget:\n",
    "                                display(HTML(result_html))\n",
    "                        return group_id\n",
    "        with output_widget:\n",
    "            clear_output(wait=True)\n",
    "            print(\"Scanning for face match...\")\n",
    "        if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "            break\n",
    "    cap.release()\n",
    "    cv2.destroyAllWindows()\n",
    "    with output_widget:\n",
    "        clear_output()\n",
    "        print(\"Webcam session ended.\")\n",
    "    return None\n",
    "\n",
    "# Main UI\n",
    "path_input = Text(value='', placeholder='Enter folder path', description='Folder Path:')\n",
    "process_button = Button(description=\"Process Images\")\n",
    "webcam_button = Button(description=\"Recognize via Webcam\")\n",
    "progress_bar = FloatProgress(value=0, min=0, max=1, description='Progress:')\n",
    "output = Output()\n",
    "\n",
    "# Global variables\n",
    "face_groups = None\n",
    "uploaded_files = None\n",
    "file_mapping = None\n",
    "output_folder = \"individual_faces_output\"\n",
    "\n",
    "def on_process_button_clicked(b):\n",
    "    global face_groups, uploaded_files, file_mapping\n",
    "    with output:\n",
    "        clear_output()\n",
    "        start_time = time.time()\n",
    "        folder_path = path_input.value.strip()\n",
    "        if not folder_path:\n",
    "            display(HTML(after_ui_html.format(\"Please enter a folder path.\")))\n",
    "            return\n",
    "        \n",
    "        progress_bar.value = 0\n",
    "        uploaded_files = load_images(folder_path, progress_bar, output)\n",
    "        if not uploaded_files:\n",
    "            display(HTML(after_ui_html.format(\"No valid image files found in the folder.\")))\n",
    "            return\n",
    "        \n",
    "        print(f\"Loaded {len(uploaded_files)} files.\")\n",
    "        progress_bar.value = 0\n",
    "        face_groups, processed_images = group_similar_faces(uploaded_files, progress_bar, output)\n",
    "        if processed_images == 0:\n",
    "            display(HTML(after_ui_html.format(\"No faces detected in the images.\")))\n",
    "            return\n",
    "        \n",
    "        print(f\"Detected {len(face_groups)} face groups.\")\n",
    "        zip_files, file_mapping = save_grouped_faces_and_zip(face_groups, output_folder, uploaded_files)\n",
    "        output_text = f\"Summary (as of {time.strftime('%Y-%m-%d %H:%M:%S')}):\\n\"\n",
    "        output_text += f\"Total images processed: {processed_images}\\n\"\n",
    "        output_text += f\"Number of unique faces detected: {len(face_groups)}\\n\"\n",
    "        output_text += f\"Execution time: {time.time() - start_time:.2f} seconds\\n\"\n",
    "        output_text += \"\\nFace Groups:\\n\"\n",
    "        for group_id, faces in face_groups.items():\n",
    "            filenames = [uploaded_files[f['filename']]['original_name'] for f in faces]\n",
    "            output_text += f\"{group_id}: {', '.join(set(filenames))}\\n\"\n",
    "        \n",
    "        if zip_files:\n",
    "            zip_path = zip_files[0]\n",
    "            relative_path = os.path.relpath(zip_path, start=os.getcwd())\n",
    "            output_text += f\"\\n<a href='{relative_path}' download='all_faces.zip'>Download all grouped faces as ZIP</a>\"\n",
    "        \n",
    "        output_text += \"\\n\\nGrouped Images:\\n\"\n",
    "        image_display = display_grouped_images(face_groups, file_mapping)\n",
    "        display(HTML(after_ui_html.format(output_text + image_display)))\n",
    "\n",
    "def on_webcam_button_clicked(b):\n",
    "    global face_groups, uploaded_files, file_mapping\n",
    "    with output:\n",
    "        clear_output()\n",
    "        if not face_groups or not uploaded_files or not file_mapping:\n",
    "            display(HTML(\"Please process images first by entering a folder path and clicking 'Process Images'.\"))\n",
    "            return\n",
    "        \n",
    "        matched_group_id = recognize_face_from_webcam(face_groups, uploaded_files, output_folder, file_mapping, output)\n",
    "        if not matched_group_id:\n",
    "            display(HTML(\"No match found or webcam session ended.\"))\n",
    "\n",
    "process_button.on_click(on_process_button_clicked)\n",
    "webcam_button.on_click(on_webcam_button_clicked)\n",
    "\n",
    "# Display UI\n",
    "display(VBox([HBox([path_input]), HBox([process_button, webcam_button]), progress_bar, output]))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {
     "21d013ec65af4bf88337b22363b972d3": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "ButtonModel",
      "state": {
       "description": "Recognize via Webcam",
       "layout": "IPY_MODEL_763f0338998b4407a3b4e876dac6a714",
       "style": "IPY_MODEL_a0aa26adbf204a7a9a8f46baa32d6110"
      }
     },
     "2dc980f41b7e4348b4f4b4e80bbd2725": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {}
     },
     "37f32a29284e4ea8852ea99d7ac619e0": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {}
     },
     "45ae14375c604644bcbcd4c2b9a8897d": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {}
     },
     "5c4d3418e0894eef9a52742f94635182": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "ButtonModel",
      "state": {
       "description": "Process Images",
       "layout": "IPY_MODEL_ced4739c909e480d9bd9bb3c914ce8eb",
       "style": "IPY_MODEL_d960ea65470d4c2a926cae37994b5240"
      }
     },
     "60453c6768094a5c962890506e3d9b3d": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "description_width": ""
      }
     },
     "62ef540471884c5797b5c97f9bf42652": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "VBoxModel",
      "state": {
       "children": [
        "IPY_MODEL_73779a23842442769bf401e13acbc1bf",
        "IPY_MODEL_b8ea5e3166634f07812dfb1441b20c47",
        "IPY_MODEL_fb638a63502e4996b36748cac089e961",
        "IPY_MODEL_92fc25d192cc48f1b26faa8e1555784f"
       ],
       "layout": "IPY_MODEL_37f32a29284e4ea8852ea99d7ac619e0"
      }
     },
     "73779a23842442769bf401e13acbc1bf": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HBoxModel",
      "state": {
       "children": [
        "IPY_MODEL_8a4c68e031b5481aa5f3dc19f504e376"
       ],
       "layout": "IPY_MODEL_dc9eafd3efea47c88607785e5d548de9"
      }
     },
     "763f0338998b4407a3b4e876dac6a714": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {}
     },
     "8a4c68e031b5481aa5f3dc19f504e376": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "TextModel",
      "state": {
       "description": "Folder Path:",
       "layout": "IPY_MODEL_2dc980f41b7e4348b4f4b4e80bbd2725",
       "placeholder": "Enter folder path",
       "style": "IPY_MODEL_a20ec8c3f58447df8eb684626d4b83b5",
       "value": "C:\\Users\\udayk\\Desktop\\images"
      }
     },
     "92fc25d192cc48f1b26faa8e1555784f": {
      "model_module": "@jupyter-widgets/output",
      "model_module_version": "1.0.0",
      "model_name": "OutputModel",
      "state": {
       "layout": "IPY_MODEL_45ae14375c604644bcbcd4c2b9a8897d",
       "msg_id": "f609273d-fabd-49c5-b237-ee495d7d061d",
       "outputs": [
        {
         "name": "stdout",
         "output_type": "stream",
         "text": "Processing 12/24: IMG-20240321-WA0017.jpg\n"
        }
       ]
      }
     },
     "a0aa26adbf204a7a9a8f46baa32d6110": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "ButtonStyleModel",
      "state": {}
     },
     "a20ec8c3f58447df8eb684626d4b83b5": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "description_width": ""
      }
     },
     "b8ea5e3166634f07812dfb1441b20c47": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HBoxModel",
      "state": {
       "children": [
        "IPY_MODEL_5c4d3418e0894eef9a52742f94635182",
        "IPY_MODEL_21d013ec65af4bf88337b22363b972d3"
       ],
       "layout": "IPY_MODEL_f4a5835fe90e4ec3a2aea115c336a241"
      }
     },
     "ced4739c909e480d9bd9bb3c914ce8eb": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {}
     },
     "d960ea65470d4c2a926cae37994b5240": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "ButtonStyleModel",
      "state": {}
     },
     "dc9eafd3efea47c88607785e5d548de9": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {}
     },
     "ef2ada02d40548ef9a0ae6b7d26f175d": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {}
     },
     "f4a5835fe90e4ec3a2aea115c336a241": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {}
     },
     "fb638a63502e4996b36748cac089e961": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "FloatProgressModel",
      "state": {
       "description": "Progress:",
       "layout": "IPY_MODEL_ef2ada02d40548ef9a0ae6b7d26f175d",
       "max": 1,
       "style": "IPY_MODEL_60453c6768094a5c962890506e3d9b3d",
       "value": 0.5
      }
     }
    },
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
